{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk1oGKQMBVFIpXjfxndMHp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vinaydubey79/MedDRA-event-coding-and-query/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "OYEJqrqQmn44",
        "outputId": "22190ee6-e55d-44e4-be81-8da6aa161611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://cd3bdd21d1ceddf9da.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cd3bdd21d1ceddf9da.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# -----------------------------------------\n",
        "# AE Coder Prototype - Complete and Fixed\n",
        "# Narrative Weighting + Site Queries + Error Handling\n",
        "# Colab Ready (Single Cell)\n",
        "# -----------------------------------------\n",
        "\n",
        "# Step 1: Install dependencies\n",
        "!pip install -q gradio pandas rapidfuzz sentence-transformers\n",
        "\n",
        "# Step 2: Write dummy dictionary CSV (clean)\n",
        "dummy_dict_content = \"\"\"id,llt_name,pt_name,soc_name,is_current\n",
        "1001,Nausea,Nausea and vomiting,Gastrointestinal disorders,True\n",
        "1002,Vomiting,Nausea and vomiting,Gastrointestinal disorders,True\n",
        "1003,Diarrhoea,Diarrhoea,Gastrointestinal disorders,True\n",
        "1004,Chest pain,Chest pain,Cardiac disorders,True\n",
        "1005,Myocardial infarction,Myocardial infarction,Cardiac disorders,True\n",
        "1006,Rash,Rash,Skin and subcutaneous tissue disorders,True\n",
        "1007,Generalized rash,Rash,Skin and subcutaneous tissue disorders,True\n",
        "1008,Itchy rash,Pruritus,Skin and subcutaneous tissue disorders,True\n",
        "1009,Wrist fracture,Fractures,Injury poisoning and procedural complications,True\n",
        "1010,Fall,Fall,Injury poisoning and procedural complications,True\n",
        "1011,Headache,Headache,Nervous system disorders,True\n",
        "1012,Fever,Pyrexia,General disorders and administration site conditions,True\n",
        "\"\"\"\n",
        "\n",
        "with open(\"dummy_dict.csv\", \"w\") as f:\n",
        "    f.write(dummy_dict_content)\n",
        "\n",
        "# Step 3: Import libraries and load model\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from rapidfuzz import fuzz, process\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"dummy_dict.csv\", dtype=str)\n",
        "df[\"is_current\"] = df[\"is_current\"].fillna(\"True\").str.lower().isin([\"true\",\"1\",\"y\"])\n",
        "df[\"norm\"] = df[\"llt_name\"].str.lower()\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "emb = model.encode(df[\"norm\"].tolist(), normalize_embeddings=True)\n",
        "\n",
        "def normalize(text):\n",
        "    t = (text or \"\").lower()\n",
        "    t = re.sub(r\"[^a-z0-9\\s/+\\-]\", \" \", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    return t\n",
        "\n",
        "def generate_site_queries(verbatim, narrative):\n",
        "    queries = []\n",
        "    v = (verbatim or \"\").lower()\n",
        "    n = (narrative or \"\").lower()\n",
        "    if \"myocardial infarction\" in n and \"chest pain\" in v:\n",
        "        queries.append(\n",
        "            \"Kindly confirm if the verbatim should be updated to 'Myocardial infarction' based on narrative details instead of 'Chest pain'.\"\n",
        "        )\n",
        "    if \"sepsis\" in n and \"fever\" in v:\n",
        "        queries.append(\n",
        "            \"Please confirm if the fever is related to sepsis as described in the narrative.\"\n",
        "        )\n",
        "    if \"rash\" in v and not any(x in n for x in [\"generalized\", \"localized\", \"site\"]):\n",
        "        queries.append(\n",
        "            \"Please specify if the rash is localized or generalized, and provide location details.\"\n",
        "        )\n",
        "    return queries if queries else [\"No additional queries detected based on input.\"]\n",
        "\n",
        "def code(verbatim, narrative):\n",
        "    try:\n",
        "        text_v = normalize(verbatim or \"\")\n",
        "        text_n = normalize(narrative or \"\")\n",
        "        if not text_v and not text_n:\n",
        "            return \"Please enter verbatim or narrative text.\", \"\", \"\"\n",
        "\n",
        "        w_narrative = min(max(len(text_n.split()) / 100, 0.3), 0.6)\n",
        "        w_verbatim = 1 - w_narrative\n",
        "\n",
        "        lex_v = process.cdist([text_v], df[\"norm\"].tolist(), scorer=fuzz.token_set_ratio)[0].astype(float) if text_v else np.zeros(len(df))\n",
        "        lex_n = process.cdist([text_n], df[\"norm\"].tolist(), scorer=fuzz.token_set_ratio)[0].astype(float) if text_n else np.zeros(len(df))\n",
        "\n",
        "        emb_v = model.encode([text_v], normalize_embeddings=True) if text_v else np.zeros((1, emb.shape[1]))\n",
        "        emb_v = emb_v.ravel() if emb_v.ndim == 2 else emb_v\n",
        "\n",
        "        emb_n = model.encode([text_n], normalize_embeddings=True) if text_n else np.zeros((1, emb.shape[1]))\n",
        "        emb_n = emb_n.ravel() if emb_n.ndim == 2 else emb_n\n",
        "\n",
        "        sem_v = (emb @ emb_v.reshape(-1,1)).ravel() * 100.0 if text_v else np.zeros(len(df))\n",
        "        sem_n = (emb @ emb_n.reshape(-1,1)).ravel() * 100.0 if text_n else np.zeros(len(df))\n",
        "\n",
        "        lex_scores = w_verbatim * lex_v + w_narrative * lex_n\n",
        "        sem_scores = w_verbatim * sem_v + w_narrative * sem_n\n",
        "        final_score = 0.6 * lex_scores + 0.4 * sem_scores\n",
        "\n",
        "        top_idx = np.argsort(-final_score)[:10]\n",
        "        cands = df.iloc[top_idx].copy()\n",
        "        cands = cands.reset_index(drop=True)\n",
        "        cands[\"score\"] = final_score[top_idx]\n",
        "\n",
        "        if cands.empty or len(cands) == 0:\n",
        "            return \"No suitable candidates found.\", \"\", \"\"\n",
        "\n",
        "        best = cands.iloc[0]\n",
        "        rationale_best = (\n",
        "            \"This term was selected because it best matches the given verbatim and narrative context \"\n",
        "            \"and is currently the preferred coding term.\"\n",
        "        )\n",
        "\n",
        "        alternates_list = []\n",
        "        for pos in range(1, min(6, len(cands))):\n",
        "            r = cands.iloc[pos]\n",
        "            lex = lex_scores[top_idx[pos]]\n",
        "            sem = sem_scores[top_idx[pos]]\n",
        "            reason = (\n",
        "                \"The wording closely matches the input.\" if lex >= sem\n",
        "                else \"The meaning is closely related to the input narrative.\"\n",
        "            )\n",
        "            alternates_list.append(\n",
        "                f\"- {r['llt_name']} → PT: {r['pt_name']} (Score: {r['score']:.1f})\\n  (Reason: {reason})\"\n",
        "            )\n",
        "        alternates = \"\\n\".join(alternates_list) if alternates_list else \"No alternates found.\"\n",
        "\n",
        "        site_queries = generate_site_queries(verbatim, narrative)\n",
        "\n",
        "        return (\n",
        "            f\"{best['llt_name']} → PT: {best['pt_name']} (SOC: {best['soc_name']}) (Score: {best['score']:.1f})\\n\\n\"\n",
        "            f\"Rationale: {rationale_best}\",\n",
        "            alternates,\n",
        "            \"\\n\".join(site_queries),\n",
        "        )\n",
        "    except Exception as e:\n",
        "        err_msg = f\"ERROR: {type(e).__name__}: {e}\"\n",
        "        return err_msg, err_msg, err_msg\n",
        "\n",
        "gr.Interface(\n",
        "    fn=code,\n",
        "    inputs=[gr.Textbox(label=\"Verbatim\"), gr.Textbox(label=\"Narrative (optional, can be long)\")],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Best LLT Match with Rationale\"),\n",
        "        gr.Textbox(label=\"Alternate LLTs with Reasons\"),\n",
        "        gr.Textbox(label=\"Site Queries / Clarifications\"),\n",
        "    ],\n",
        "    title=\"AE Coder Prototype Demo with Narrative Weighting and Site Queries\",\n",
        "    description=\"Demo using a dummy dictionary (not MedDRA). Enter verbatim and narrative to get coding suggestions, alternate options, and queries for clarifications.\",\n",
        ").launch(share=True)\n"
      ]
    }
  ]
}